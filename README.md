# 100-Days-of-ML
The aim is to comprehensively revise essential statistics, machine learning algorithms, state of art models and learn to develop end-to-end products using machine learning and deep learning 
### Day 1 (24-03-20) : Binary Classification
- Studied Classification and various approaches to achieve enhanced results 
- Implemented a basic network for Binary Classification using Tensorflow
- Learnt to compress Tensorflow Models to TfLite Model for Binary Classification on Dogs vs Cats Dataset
- Worked on developing an end-to-end Flutter Application which can perform Cats vs Dogs Classification with TfLite as backend
- Model: <a href="https://github.com/vgaurav3011/100-Days-of-ML/blob/master/Day%201/catsvsdogs.ipynb">Link</a> <br/>
<img src="https://github.com/vgaurav3011/100-Days-of-ML/blob/master/Day%201/cat%20vs%20dog%20app%20flutter/cat.jpeg" height=400>                     <img src="https://github.com/vgaurav3011/100-Days-of-ML/blob/master/Day%201/cat%20vs%20dog%20app%20flutter/dog.jpeg" height=400 style="padding:10px;"> <br/>
### Day 2 (25-03-20) : Regularization
- Worked on learning different techniques to handle overfitting of a model
- Studied L1, L2 regularization and dropout regularization from Andrew NG deeplearning.ai course
- Completed the assignment on regularization in Week 1 of the course
- Studied visual intuition of regularization: <a href="https://towardsdatascience.com/a-visual-intuition-for-regularization-in-deep-learning-fe904987abbb">Link</a><br/>
- Studied Tensorflow implementation of Dropout from Lei Mao's Blog: <a href="https://leimao.github.io/blog/Dropout-Explained/">Link</a>
- Notebook Link: <a href="https://github.com/vgaurav3011/100-Days-of-ML/blob/master/Day%202/Regularization.ipynb">Click Here</a><br/>
### Day 3 (26-03-20) : Generative Adversarial Networks
- Studied basics of Generative Adversarial Networks (GANs) and their applications
- Worked on implementing a simple DCGAN to reconstruct MNIST images
- Will be working on studying GANs in depth
- Reference: <a href="https://blog.floydhub.com/gans-story-so-far/">Link</a>
- Model: <a href="https://github.com/vgaurav3011/100-Days-of-ML/blob/master/Day%203/DCGAN.ipynb">Link</a> <br/>
<img src="https://raw.githubusercontent.com/vgaurav3011/100-Days-of-ML/master/images/dcgan.gif"> <br/>
### Day 4 (27-03-20) : Neural Style Transfer
- Studied the concepts of convolution neural networks and their working process
- Implemented a simple style transfer network using pretrained weights and VGG-16 
- Studied the concept of loss function and hyperparameter tuning from Andrew NG course
- Model: <a href="https://github.com/vgaurav3011/100-Days-of-ML/blob/master/Neural_Style_Transfer.ipynb">Link</a><br/>
<img src="https://raw.githubusercontent.com/vgaurav3011/100-Days-of-ML/master/images/1.jpg" width=200 height=200>
<img src="https://raw.githubusercontent.com/vgaurav3011/100-Days-of-ML/master/images/2.jpg" width=200 height=200> 
<img src="https://raw.githubusercontent.com/vgaurav3011/100-Days-of-ML/master/images/download.png" widht=200 height=200><br/>

### Day 5 (28-03-20) : Supervised Learning: Regression
- Studied the concepts of Regression and Classification from Introduction to Machine Learning by Udacity (GaTech)
- Implemented feature engineering, preprocessing and scaling on Black Friday Data in dataset-1 folder 
- Studied ElasticNet, Lasso, Ridge, Linear, AdaBoost, Random Forest Regression, Gradient Boosting and applied the same on the dataset
- Studied the basics of XGBoosting and its applications
- Implemented a Black Friday Sales Web App for prediction using the models with Flask Framework and Pickle in backend
- Model: <a href="https://github.com/vgaurav3011/100-Days-of-ML/blob/master/Day%205/Black-Friday.ipynb">Link</a><br/>
<img src="https://raw.githubusercontent.com/vgaurav3011/100-Days-of-ML/master/images/output_flask.gif"> <br/>

### Day 6 (29-03-20) : Supervised Learning: Linear Regression and Gradient Descent
- Studied the concept of Linear Regression in depth from multiple blogs
- Read the Stanford UFDL notes on Gradient Descent and Stochastic Gradient Descent at <a href="http://ufldl.stanford.edu/tutorial/supervised/OptimizationStochasticGradientDescent/">Link</a> <br/>
- Completed implementation of Gradient Descent with Linear Regression from scratch using only mathematics through Numpy in Python.
- Studied the background mathematics of Gradient Descent and Regression
### Day 7 (30-03-20) : Optimization Algorithms and Hyperparameter Tuning
- Studied and implemented the concept of Mini Batch Gradient Descent
- Implemented the concept of gradient checking and how it boosts training time
- Studied the use of exponential weighted averages and use of momentum to speed up training processes
- Studied the various alternative optimization algorithms and learnt to implement ADAM and RMSProp from scratch
- Finished the deep learning course 2 by Andrew NG Stanford and studied the theoretical details of the concepts.
<img src="https://raw.githubusercontent.com/vgaurav3011/100-Days-of-ML/master/images/certy-1.png" width=700 height=400><br/>
### Day 8 (31-03-20) : Structuring Machine Learning Projects and Basics of Tensorflow
- Studied the fine tuning of networks
- Studied train/dev/test set distribution techniques
- Studied sampling techniques and finished the third course of Andrew NG
- Read use of dockers for deployment of models
- Studied the blog on real time deployment of models at FloydHub: <a href="https://blog.floydhub.com/structuring-and-planning-your-machine-learning-project/">Link</a> <br/>
<img src="https://raw.githubusercontent.com/vgaurav3011/100-Days-of-ML/master/images/certy-2.png" width=700 height=400><br/> <br/>
### Day 9 (01-04-20) : UNet for Biomedical Image Segmentation
- Studied the UNet Architecture from the state of art paper: <a href="https://arxiv.org/pdf/1505.04597.pdf">Link</a>
- Studied the concepts of upsampling, encoder-decoder architecture integration into UNet
- Read and made notes of the blog by Ayyuce Kizrak: <a href="https://heartbeat.fritz.ai/deep-learning-for-image-segmentation-u-net-architecture-ff17f6e4c1cf">Link</a>
- Designed a custom data generator for Nuclei Segmentation from Biomedical Images
- Dataset Link: <a href="https://www.kaggle.com/c/data-science-bowl-2018/rules">Link</a>
- The data was part of the Data Science Bowl 2018
- Implemented a UNet architecture after analysing the paper
- Model: <a href="https://github.com/vgaurav3011/100-Days-of-ML/blob/master/Day%209/model.ipynb">Link</a>
<br/>
<img src="https://github.com/vgaurav3011/100-Days-of-ML/blob/master/Day%209/input.png"><img src="https://github.com/vgaurav3011/100-Days-of-ML/blob/master/Day%209/output.png"> <br/>
### Day 10(02-04-20)
